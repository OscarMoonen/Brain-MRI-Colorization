{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akWQNS4WVrmg",
        "outputId": "ffe94b93-7a05-46e5-ed6e-2299938c9e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-73330d7f-d4f7-8c9c-f406-1557b523ada1)\n"
          ]
        }
      ],
      "source": [
        "# Producing structure preserving MRI colorizations with biologically plausible color distributions using a CycleGAN\n",
        "# Oscar Moonen\n",
        "# Version: 05-2022\n",
        "\n",
        "### !!This Model is made to run with Google Colab!! ###\n",
        "\n",
        "# Current GPU-Type\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XFl_WzZstNAj"
      },
      "outputs": [],
      "source": [
        "#### Settings ####\n",
        "numEpochs = 100        # Epochs to Run for\n",
        "batch = 6              # Batch Size    \n",
        "num_blocks = 10        # ResNet blocks\n",
        "learningRate = 0.0002  # Learning Rate\n",
        "UpdateAfterStep = 1    # Update learning rate after epoch\n",
        "UpdateBy = 0.95        # Update by: LR*UpdateBy\n",
        "b1 = 0.5               # Momentum parameters\n",
        "b2 = 0.999\n",
        "\n",
        "lambdaAdversarial = 1  # Weighting Generator Losses\n",
        "lambdaCycle = 1\n",
        "lambdaSSIM = 1        \n",
        "\n",
        "transpose2D = False    # Upsample technique, default= upscale -> convolution\n",
        "augmentPolicy = \"All\"  # Differentiable Augmentations to apply (other: color, translation, cutout)\n",
        "saveAfter = 500        # Plot intermediate results / Save model after # Batches\n",
        "\n",
        "\n",
        "### Folders ###\n",
        "prefixTest = \"/content/drive/MyDrive/\"                     # Intermediate plotting source MRI scans\n",
        "prefixInter = \"/content/drive/MyDrive/\"                    # Intermediate plotting output folder\n",
        "prefixModel = \"/content/drive/MyDrive/\"                    # Save location Generator MRI->Color\n",
        "cryoDataFrame = \"/content/drive/MyDrive/Data/Cryodf.pkl\"   # Dataset locations\n",
        "MRIDataFrame = \"/content/drive/MyDrive/Data/MRIdf.pkl\"\n",
        "\n",
        "prefixSave = \"MyTestRun\"                                   # Prefix to add to output Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sD705bl3wCx",
        "outputId": "7896bd45-8f05-4de9-f59f-803f047d5419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: piqa in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from piqa) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from piqa) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.0->piqa) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->piqa) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->piqa) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->piqa) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (1.24.3)\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Device: cuda\n",
            "dataPoints Cryo: 2698\n",
            "dataPoints MRI: 5881\n"
          ]
        }
      ],
      "source": [
        "# Imports Statements #\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as TorchTransforms \n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import random\n",
        "import IPython\n",
        "from torch.autograd import Variable\n",
        "import os , itertools\n",
        "from torch.optim.lr_scheduler import  StepLR\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from math import log10, sqrt, exp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "## Colab compatability installs ##\n",
        "!pip install piqa\n",
        "from piqa import SSIM\n",
        "!pip3 install pickle5\n",
        "import pickle5 as pickle\n",
        "\n",
        "## Mount Google Drive ##\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "\n",
        "## Load Datasets ##\n",
        "with open(cryoDataFrame, \"rb\") as fh:\n",
        "    Cryodf= pickle.load(fh) \n",
        "with open(MRIDataFrame, \"rb\") as fh:\n",
        "    MRIdf= pickle.load(fh) \n",
        "\n",
        "print()     \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "dataPointsCryo = Cryodf.shape[0]\n",
        "dataPointsMRI= MRIdf.shape[0]\n",
        "print(\"dataPoints Cryo:\", dataPointsCryo)\n",
        "print(\"dataPoints MRI:\", dataPointsMRI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TB__vi3mtNAr"
      },
      "outputs": [],
      "source": [
        "# Create Tensors of MRI scans used in the intermediate plots\n",
        "# Used in the intermediate plots\n",
        "# name the desired images: 0,1,2,3,4.png (should be 256x256)\n",
        "\n",
        "def makeTestTensors():  \n",
        "    prefix = prefixTest   # File location\n",
        "    suffix = \".png\"       # Format\n",
        "    tensorList = []       # Store tensors\n",
        "    for i in range(5):\n",
        "        path = prefix + str(i) + suffix # File Path\n",
        "        testImage = np.asarray(Image.open(path)) # Load with PIL image\n",
        "        testImageScaled = (testImage/127.5) -1   # Normalize from [0,256] to [-1,1]  \n",
        "        testTensor = torch.tensor(testImageScaled.astype(float).T, requires_grad=False).float().unsqueeze(0) # Create tensor with correct shape (B, C, H, W)\n",
        "        tensorList.append(testTensor)\n",
        "    return tensorList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m6QF4AsvqgXS"
      },
      "outputs": [],
      "source": [
        "# Saves the output of the intermediate MRI images to Drive folder\n",
        "\n",
        "def saveTestImages(genList, reconList, epoch, i):\n",
        "    fig, ax = plt.subplots(5, 3) # Create plot of 15 images\n",
        "    fig.set_size_inches(15, 15)\n",
        "    prefix = prefixTest # File location\n",
        "    add = prefixInter   # Save location\n",
        "    suffix = \".png\"\n",
        "    for i, (gen, recon) in enumerate(zip(genList, reconList)): # Go over received list of colorizations and reconstructions\n",
        "        path = prefix + str(i) + suffix # Retrieve the original input MRI\n",
        "        gen = np.clip(gen, 0, 255)      # Colorization\n",
        "        recon = np.clip(recon, 0, 255)  # Reconstruction\n",
        "        input = np.asarray(Image.open(path))\n",
        "        ax[i][0].imshow(input)\n",
        "        ax[i][0].axis(\"off\")\n",
        "        ax[i][0].title.set_text('Input')\n",
        "        ax[i][1].imshow(gen)\n",
        "        ax[i][1].axis(\"off\")\n",
        "        ax[i][1].title.set_text('Generated')\n",
        "        ax[i][2].imshow(recon)\n",
        "        ax[i][2].axis(\"off\")\n",
        "        ax[i][2].title.set_text('Reconstructed')\n",
        "    fig.set_size_inches(15, 15)\n",
        "    plt.savefig(add + prefixSave + \"-\" + str(epoch) + suffix)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "adWpy0I9q_4l"
      },
      "outputs": [],
      "source": [
        "# Saves the loss plots intermediately\n",
        "# Smooths the errors by averaging over 10 batches\n",
        "\n",
        "def saveErrorPlots(Generators_Loss_List, Discriminator_M_Loss_List, Discriminator_C_Loss_List, adversarial_loss_list , cycle_loss_list, ssim_loss_list, Discriminator_C_FakeDecision_List, SSIMtrack, epoch, i):\n",
        "    add = prefixInter\n",
        "    losses = [Generators_Loss_List, adversarial_loss_list , cycle_loss_list , ssim_loss_list, Discriminator_C_FakeDecision_List, Discriminator_M_Loss_List, Discriminator_C_Loss_List, SSIMtrack] # Losses to plot\n",
        "    lossesNames = [\"G_Total\", \"Adversarial_loss\" , \"Cycle_loss\" , \"SSIM_loss\", \"C_Fake_Conf\", \"D_M\", \"D_C\", \"SSIM_score\"] # Relevant names\n",
        "    \n",
        "    for k, loss in enumerate(losses): # Smooth error plots by averaging\n",
        "      lossList = [sum(i) for i in zip(*([iter(loss)]*10))]\n",
        "      lossList = [(i/10) for i in lossList]\n",
        "      losses[k] = lossList\n",
        "\n",
        "    fig, ax = plt.subplots(4,1)\n",
        "    ax[0].set_title('G Losses', size = 24)\n",
        "    for name, lossList in zip(lossesNames[:4],losses[:4]):\n",
        "          ax[0].plot(lossList, label=name)\n",
        "    ax[0].legend(loc=\"upper right\")\n",
        "    ax[0].set_ylim([0, 3])\n",
        "\n",
        "    ax[1].set_title('D_M Loss', size = 24)\n",
        "    ax[1].plot(Discriminator_M_Loss_List, label='D_M Loss')\n",
        "    ax[1].set_ylim([0, 1])\n",
        "    \n",
        "    ax[0].set_title('D_C Loss', size = 24)\n",
        "    for name, lossList in zip(lossesNames[5:7],losses[5:7]):\n",
        "          ax[2].plot(lossList, label=name)\n",
        "    ax[2].legend(loc=\"upper right\")\n",
        "    ax[2].set_ylim([0, 1])\n",
        "\n",
        "    ax[3].set_title('SSIM score', size = 24)\n",
        "    ax[3].plot(SSIMtrack, label=\"SSIM\")\n",
        "    ax[3].set_ylim([0, 1])\n",
        "    ax[3].legend(loc=\"upper right\")\n",
        "\n",
        "\n",
        "    # Discriminator_C_FakeDecision_List = [sum(i) for i in zip(*([iter(Discriminator_C_FakeDecision_List)]*10))]\n",
        "    # Discriminator_C_FakeDecision_List = [(i/10) for i in Discriminator_C_FakeDecision_List]\n",
        "    # Discriminator_M_Loss_List = [sum(i) for i in zip(*([iter(Discriminator_M_Loss_List)]*10))]\n",
        "    # Discriminator_M_Loss_List = [(i/10) for i in Discriminator_M_Loss_List]\n",
        "    # Discriminator_C_Loss_List = [sum(i) for i in zip(*([iter(Discriminator_C_Loss_List)]*10))]\n",
        "    # Discriminator_C_Loss_List = [(i/10) for i in Discriminator_C_Loss_List]\n",
        "\n",
        "\n",
        "    # ax[1].set_title('D MRI Loss', size = 24)\n",
        "    # ax[1].plot(Discriminator_M_Loss_List[start:], label=\"Discriminator M\")\n",
        "    # ax[1].set_ylim([0, 0.75])\n",
        "    # ax[2].set_title('D Cryo', size = 24)\n",
        "    # ax[2].plot(Discriminator_C_FakeDecision_List[start:], label=\"Fake Des\")\n",
        "    # ax[2].plot(Discriminator_C_Loss_List[start:], label=\"Discriminator C\")\n",
        "    # ax[2].legend(loc=\"upper right\")\n",
        "    # ax[2].set_ylim([0, 0.75])\n",
        "    # SSIMtrack = [sum(i) for i in zip(*([iter(SSIMtrack)]*10))]\n",
        "    # SSIMtrack = [(i/10) for i in SSIMtrack]\n",
        "    # ax[3].set_title('SSIM', size = 24)\n",
        "    # ax[3].plot(SSIMtrack[start:], label=\"SSIM\")\n",
        "    # ax[3].set_ylim([0, 1])\n",
        "    # ax[3].legend(loc=\"upper right\")\n",
        "    fig.set_size_inches(30, 20)\n",
        "    plt.savefig(add + prefixSave +\"-\" + str(epoch) +'-Errors.png')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "71OXzdY_u-6y"
      },
      "outputs": [],
      "source": [
        "# Save the Generator that creates colorizations every intermediate period\n",
        " \n",
        "def saveModel(epoch, Generator_MC):\n",
        "        PATH = prefixModel + prefixSave + str(epoch) + \"model.pt\"\n",
        "        torch.save({'GMC_state_dict': Generator_MC.state_dict(),}, PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wfee1I6HH_La"
      },
      "outputs": [],
      "source": [
        "# Soft data augmentation pipeline\n",
        "\n",
        "# Tutorial: https://imgaug.readthedocs.io/en/latest/source/examples_basics.html#a-standard-use-case\n",
        "\n",
        "seq = iaa.Sequential([                                                        # Soft Augmentation Pipeline:\n",
        "    iaa.Fliplr(0.5),                                                          # Flip\n",
        "    iaa.Crop(percent=(0, 0.1)),                                               # Crop\n",
        "    iaa.Sometimes(0.5,iaa.GaussianBlur(sigma=(0, 0.5))),                      # Blur\n",
        "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # Noise\n",
        "    iaa.Affine(                                                               # Translation / Rotation\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        shear=(-8, 8))], random_order=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6BYU7P833wC0"
      },
      "outputs": [],
      "source": [
        "# Data Loaders\n",
        "\n",
        "# Tutorial: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html \n",
        "\n",
        "class CryoDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.file_names = Cryodf['fileName'].tolist()  # List of datafile names\n",
        "    def __getitem__(self, index):\n",
        "        Cryodf.sample(frac=1)                          # Shuffle \n",
        "        file = Cryodf.loc[Cryodf['fileName'] == self.file_names[index]]['file'].item() # Retrieve from df\n",
        "        file = seq(images=file[None,:,:,:])[0]         # Use soft augmentation pipeline    \n",
        "        file = (file/127.5) -1                         # Normalize to [-1:1]\n",
        "        return torch.tensor(file.astype(float).T, requires_grad=True).float() # Create tensor with (B,C,H,W) shape. \n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.file_names = MRIdf['fileName'].tolist()\n",
        "    def __getitem__(self, index):\n",
        "        MRIdf.sample(frac=1)\n",
        "        file = MRIdf.loc[MRIdf['fileName'] == self.file_names[index]]['file'].item()\n",
        "        file = seq(images=file[None,:,:,:])[0]\n",
        "        file = (file/127.5) -1\n",
        "        return torch.tensor(file.astype(float).T, requires_grad=True).float()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "CryoLoader = torch.utils.data.DataLoader(CryoDataset(), batch_size = batch, shuffle = True)\n",
        "MRILoader = torch.utils.data.DataLoader(MRIDataset(), batch_size = batch, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cNEGNMJT3wC2"
      },
      "outputs": [],
      "source": [
        "# Creates an image pool of recently generated images\n",
        "\n",
        "# Citation:\n",
        "# Yun A. (2019). CycleGAN-pytorch. Kaggle. https://www.kaggle.com/code/pipiking/cyclegan-pytorch/script\n",
        "\n",
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images.data:\n",
        "            image = torch.unsqueeze(image, 0)\n",
        "            if self.num_imgs < self.pool_size:\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = random.randint(0, self.pool_size-1)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "        return_images = Variable(torch.cat(return_images, 0))\n",
        "        return return_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "59lMIt3tdqTF"
      },
      "outputs": [],
      "source": [
        "# Differentiable Augmentations\n",
        "\n",
        "# Citation: \n",
        "# Differentiable Augmentation for Data-Efficient GAN Training\n",
        "# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n",
        "# https://arxiv.org/pdf/2006.10738\n",
        "# (Github: https://github.com/mit-han-lab/data-efficient-gans)\n",
        "\n",
        "def DiffAugment(x, policy='', channels_first=True):\n",
        "    if policy:\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "        for p in policy.split(','):\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x)\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "def rand_brightness(x):\n",
        "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
        "    return x\n",
        "\n",
        "def rand_saturation(x):\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
        "    return x\n",
        "\n",
        "def rand_contrast(x):\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
        "    return x\n",
        "\n",
        "def rand_translation(x, ratio=0.125):\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2).contiguous()\n",
        "    return x\n",
        "\n",
        "def rand_cutout(x, ratio=0.5):\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "AUGMENT_FNS = { # Augmentation policies\n",
        "    'All' : [rand_brightness, rand_saturation, rand_contrast, rand_cutout, rand_translation], \n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'translation': [rand_translation],\n",
        "    'cutout': [rand_cutout],}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A0aUhpHB3wC5"
      },
      "outputs": [],
      "source": [
        "# Generator Architecture\n",
        "\n",
        "# Written with guidance from:\n",
        "# Ashwath B. (2020). CycleGAN Translating Apples->Oranges [PyTorch]. Kaggle. https://www.kaggle.com/code/balraj98/cyclegan-translating-apples-oranges-pytorch/notebook\n",
        "# Yun A. (2019). CycleGAN-pytorch. Kaggle. https://www.kaggle.com/code/pipiking/cyclegan-pytorch/script\n",
        "\n",
        "# Original Paper:\n",
        "# Zhu J., Park T., Isola P., and Efros A.. \"Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\", in IEEE International Conference on Computer Vision (ICCV), 2017.\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.convRes = nn.Conv2d(256,256,3)\n",
        "        self.reflect1 = nn.ReflectionPad2d(1)\n",
        "        self.norm256 = nn.InstanceNorm2d(256)\n",
        "        self.ReLu = nn.ReLU(inplace=True)\n",
        "    def block(self, x):\n",
        "        x = self.reflect1(x)\n",
        "        x = self.ReLu(self.norm256(self.convRes(x)))\n",
        "        x = self.reflect1(x)\n",
        "        x = self.norm256(self.convRes(x))\n",
        "        return x\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "  \n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, 7, stride = 1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, stride = 2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, stride = 2, padding=1)\n",
        "        self.block = ResidualBlock()\n",
        "        self.conv4 = nn.Conv2d(256, 128, 3, stride = 1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 64, 3, stride = 1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(64, 3, 7, stride = 1, padding=0)\n",
        "\n",
        "        self.reflect1 = nn.ReflectionPad2d(1)\n",
        "        self.reflect3 = nn.ReflectionPad2d(3)\n",
        "        self.ReLu = nn.ReLU(inplace=True)\n",
        "        self.tanH = nn.Tanh()\n",
        "        if transpose2D:\n",
        "          self.upsample1 = nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1)\n",
        "          self.upsample2 = nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1)\n",
        "        else:\n",
        "          self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.norm256 = nn.InstanceNorm2d(256)\n",
        "        self.norm128 = nn.InstanceNorm2d(128)\n",
        "        self.norm64 = nn.InstanceNorm2d(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.reflect3(x)\n",
        "        x = self.ReLu(self.norm64 (self.conv1(x))) #1\n",
        "        x = self.ReLu(self.norm128(self.conv2(x))) #2\n",
        "        x = self.ReLu(self.norm256(self.conv3(x))) #3\n",
        "\n",
        "        for i in range(num_blocks): \n",
        "            x = self.block(x)\n",
        "        if transpose2D:\n",
        "            x = self.ReLu(self.norm128(self.upsample1(x))) #4\n",
        "            x = self.ReLu(self.norm64(self.upsample2(x))) #5\n",
        "        else:\n",
        "            x = self.ReLu(self.norm128(self.conv4(self.upsample(x)))) #4\n",
        "            x = self.ReLu(self.norm64(self.conv5(self.upsample(x))))  #5   \n",
        "        x = self.reflect3(x)\n",
        "        x = self.tanH(self.conv6(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GNu0inH33wC8"
      },
      "outputs": [],
      "source": [
        "# Discriminator Architecture\n",
        "\n",
        "# Written with guidance from:\n",
        "# Ashwath B. (2020). CycleGAN Translating Apples->Oranges [PyTorch]. Kaggle. https://www.kaggle.com/code/balraj98/cyclegan-translating-apples-oranges-pytorch/notebook\n",
        "# Yun A. (2019). CycleGAN-pytorch. Kaggle. https://www.kaggle.com/code/pipiking/cyclegan-pytorch/script\n",
        "\n",
        "# Original Paper:\n",
        "# Zhu J., Park T., Isola P., and Efros A.. \"Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\", in IEEE International Conference on Computer Vision (ICCV), 2017.\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, 4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 4, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(512, 1, 4, stride=1, padding=1)\n",
        "    \n",
        "        self.norm512 = nn.InstanceNorm2d(512)\n",
        "        self.norm128 = nn.InstanceNorm2d(128)\n",
        "        self.norm256 = nn.InstanceNorm2d(256)\n",
        "        self.zeroPad = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "        self.ReLu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ReLu(self.conv1(x))               #1\n",
        "        x = self.ReLu(self.norm128(self.conv2(x))) #2\n",
        "        x = self.ReLu(self.norm256(self.conv3(x))) #3\n",
        "        x = self.ReLu(self.norm512(self.conv4(x))) #4\n",
        "        x = self.conv5(self.zeroPad(x))            #5 \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "_CYayAhN3wC9",
        "outputId": "44df079e-fb5f-454e-d898-bd295d7924bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0 | 189/449"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generator LR: 0.0002"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "D_fake cryo: 0.49"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SSIM:0.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5eaa721a2a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mreconList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensorList\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Put intermediate tensors through the G_MC and G_CM to retrieve results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                         \u001b[0moutGenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator_MC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                         \u001b[0moutRecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator_CM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutGenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                         \u001b[0moutGenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutGenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "### Initialize Losses ###\n",
        "adverLoss = torch.nn.MSELoss().to(device)\n",
        "cycleLoss = torch.nn.L1Loss().to(device)\n",
        "ssim = SSIM().cuda()\n",
        "\n",
        "### Initialize Models ###\n",
        "Generator_MC = Generator().to(device)        #MC = MRI->Color\n",
        "Generator_CM = Generator().to(device)        #CM = Color->MRI\n",
        "Discriminator_M = Discriminator().to(device) # M = MRI\n",
        "Discriminator_C = Discriminator().to(device) # C = Color\n",
        "\n",
        "### Optimization ###\n",
        "lr=learningRate \n",
        "optimizer_Generator = torch.optim.Adam(itertools.chain(Generator_MC.parameters(), Generator_CM.parameters()), lr=lr, betas=(b1,b2))\n",
        "optimizer_Discriminator_M = torch.optim.Adam(Discriminator_M.parameters(), lr=lr, betas=(b1,b2))\n",
        "optimizer_Discriminator_C = torch.optim.Adam(Discriminator_C.parameters(), lr=lr, betas=(b1,b2))\n",
        "scheduler = StepLR(optimizer_Generator, step_size= UpdateAfterStep, gamma=UpdateBy)\n",
        "\n",
        "### Tracking Losses ###\n",
        "Generators_Loss_List = []\n",
        "Discriminator_M_Loss_List = []\n",
        "Discriminator_C_Loss_List = []\n",
        "adversarial_loss_list , cycle_loss_list , ssim_loss_list, SSIMtrack, Discriminator_C_FakeDecision_List = [], [], [], [], []\n",
        "\n",
        "### Initialize Image Pool ###\n",
        "num_pool = 50\n",
        "fake_MRI_pool = ImagePool(num_pool)\n",
        "fake_Cryo_pool = ImagePool(num_pool)\n",
        "\n",
        "### Display Progress ###\n",
        "trackSave = 0 \n",
        "batches = ((dataPointsCryo-1)// batch) \n",
        "updateProgress = display(IPython.display.Pretty('Starting'), display_id=True)\n",
        "updateLR = display(IPython.display.Pretty('Starting'), display_id=True)\n",
        "updateD = display(IPython.display.Pretty('Starting'), display_id=True)\n",
        "updateSSIM = display(IPython.display.Pretty('Starting'), display_id=True)\n",
        "\n",
        "### Train Model ###\n",
        "for epoch in range(numEpochs):\n",
        "    if epoch != 0:\n",
        "        scheduler.step() # Decrease learning rate by step size\n",
        "\n",
        "    for i, (cryoImage, MRIImage) in enumerate(zip(CryoLoader, MRILoader)):\n",
        "        # Update Progress\n",
        "        trackSave += 1  \n",
        "        updateProgress.update(IPython.display.Pretty(str(epoch)+ \" | \" + str(i) + \"/\" + str(batches)))\n",
        "        updateLR.update(IPython.display.Pretty(\"Generator LR: \" + str(optimizer_Generator.param_groups[0]['lr'])))\n",
        "        updateD.update(IPython.display.Pretty(\"D_fake cryo: \" +  str(round(sum(Discriminator_C_FakeDecision_List[-2*batch:])/(2*batch), 2))))\n",
        "        updateSSIM.update(IPython.display.Pretty( \"SSIM:\" +  str(round(sum(SSIMtrack[-2*batch:])/(2*batch), 2))  ))\n",
        "        \n",
        "        # Data to device\n",
        "        Real_C = cryoImage.to(device)\n",
        "        Real_M = MRIImage.to(device)\n",
        "\n",
        "        if i%2 == 0: # Update every two batches\n",
        "\n",
        "              # G_MC\n",
        "              Gen_C = Generator_MC(Real_M)                         # Gen color image\n",
        "              Gen_C_Aug = DiffAugment(Gen_C, policy=augmentPolicy) # Diff augment\n",
        "              Gen_C_Aug = torch.clip(Gen_C_Aug, min=-1, max=1)     \n",
        "              Discriminator_C_FakeDecision = Discriminator_C(Gen_C_Aug) # Confidence of D_C\n",
        "              Discriminator_C_FakeDecision_List.append(  np.mean(Discriminator_C_FakeDecision.detach().cpu().numpy()) ) # Average loss\n",
        "              Generator_MC_Loss = adverLoss(Discriminator_C_FakeDecision, Variable(torch.ones(Discriminator_C_FakeDecision.size()), requires_grad= False).to(device) ) # Adversarial losss\n",
        "              Reconstructed_M = Generator_CM(Gen_C)                # Reconstruct image\n",
        "              Forward_Cycle_Loss = cycleLoss(Reconstructed_M, Real_M) # Reconstruction loss\n",
        "              Gen_C_RGB = ((Gen_C+1)/2)                            # Change range to [0,1] for calculation of SSIM with package\n",
        "              Real_M_RGB = ((Real_M+1)/2)\n",
        "              ssim_temp = ssim(Real_M_RGB, Gen_C_RGB)\n",
        "              ssim_out_C = 1 - ssim(Real_M_RGB, Gen_C_RGB)          # SSIM Loss\n",
        "              SSIMtrack.append(ssim_temp.detach().item())           # Track SSIM between M and C\n",
        "\n",
        "              # G_CM\n",
        "              Gen_M = Generator_CM(Real_C)\n",
        "              Gen_M_Aug = DiffAugment(Gen_M, policy=augmentPolicy)\n",
        "              Gen_M_Aug = torch.clip(Gen_M_Aug, min=-1, max=1) \n",
        "              Discriminator_M_FakeDecision = Discriminator_M(Gen_M_Aug)   \n",
        "              Generator_CM_Loss = adverLoss(Discriminator_M_FakeDecision, Variable(torch.ones(Discriminator_M_FakeDecision.size()), requires_grad= False).to(device) )\n",
        "              Reconstructed_C = Generator_MC(Gen_M)\n",
        "              Backward_Cycle_Loss = cycleLoss(Reconstructed_C, Real_C)\n",
        "              Gen_M_RGB = ((Gen_M+1)/2)\n",
        "              Real_C_RGB = ((Real_C+1)/2)\n",
        "              ssim_out_M = 1 - ssim(Real_C_RGB, Gen_M_RGB)\n",
        "              \n",
        "              # G optimization\n",
        "              ssim_out = (ssim_out_M + ssim_out_C) * 0.5\n",
        "              adversarial_loss_list.append(lambdaAdversarial*(Generator_MC_Loss.detach() + Generator_CM_Loss.detach()).item())\n",
        "              cycle_loss_list.append(   lambdaCycle*(Forward_Cycle_Loss.detach() + Backward_Cycle_Loss.detach()).item()  )\n",
        "              ssim_loss_list.append(   lambdaSSIM*(ssim_out.detach()).item()  )\n",
        "              Generators_Loss = lambdaSSIM*ssim_out + lambdaAdversarial*(Generator_MC_Loss + Generator_CM_Loss) + lambdaCycle*(Forward_Cycle_Loss + Backward_Cycle_Loss)\n",
        "              Generators_Loss_List.append(Generators_Loss.item())\n",
        "              optimizer_Generator.zero_grad()\n",
        "              Generators_Loss.backward()\n",
        "              optimizer_Generator.step()\n",
        "\n",
        "        # D_M\n",
        "        Real_M_Aug = DiffAugment(Real_M.detach().requires_grad_(True), policy=augmentPolicy)    # Diff augment\n",
        "        Discriminator_M_RealDecision = Discriminator_M(Real_M_Aug)                              # Confidence on real image\n",
        "        Discriminator_M_RealLoss = adverLoss(Discriminator_M_RealDecision, Variable(torch.ones(Discriminator_M_RealDecision.size()), requires_grad= False).to(device) )\n",
        "        Gen_M_Pooled = fake_MRI_pool.query(Gen_M.detach())                                      # Pool generated image\n",
        "        Gen_M_Pooled_Aug = DiffAugment(Gen_M_Pooled.requires_grad_(True), policy=augmentPolicy) # Diff augment\n",
        "        Discriminator_M_FakeDecision = Discriminator_M(Gen_M_Pooled_Aug)                        # Confidence on fake image\n",
        "        Discriminator_M_FakeLoss = adverLoss(Discriminator_M_FakeDecision, Variable(torch.zeros(Discriminator_M_FakeDecision.size()), requires_grad= False).to(device) )\n",
        "        # D_M Optimization\n",
        "        Discriminator_M_Loss = (Discriminator_M_RealLoss + Discriminator_M_FakeLoss) * 0.5\n",
        "        Discriminator_M_Loss_List.append(Discriminator_M_Loss.item())\n",
        "        optimizer_Discriminator_M.zero_grad()\n",
        "        Discriminator_M_Loss.backward()\n",
        "        optimizer_Discriminator_M.step()\n",
        "\n",
        "        # D_C\n",
        "        Real_C_Aug = DiffAugment(Real_C.detach().requires_grad_(True), policy=augmentPolicy)\n",
        "        Discriminator_C_RealDecision = Discriminator_C(Real_C_Aug)\n",
        "        Discriminator_C_RealLoss = adverLoss(Discriminator_C_RealDecision, Variable(torch.ones(Discriminator_C_RealDecision.size()), requires_grad= False).to(device) )\n",
        "        Gen_C_Pooled = fake_Cryo_pool.query(Gen_C.detach())\n",
        "        Gen_C_Pooled_Aug = DiffAugment(Gen_C_Pooled.requires_grad_(True), policy=augmentPolicy)\n",
        "        Discriminator_C_FakeDecision = Discriminator_C(Gen_C_Pooled_Aug)\n",
        "        Discriminator_C_FakeLoss = adverLoss(Discriminator_C_FakeDecision, Variable(torch.zeros(Discriminator_C_FakeDecision.size()), requires_grad= False).to(device) )\n",
        "        # D_C Optimization\n",
        "        Discriminator_C_Loss = (Discriminator_C_RealLoss + Discriminator_C_FakeLoss) * 0.5\n",
        "        Discriminator_C_Loss_List.append(Discriminator_C_Loss.item())\n",
        "        optimizer_Discriminator_C.zero_grad()\n",
        "        Discriminator_C_Loss.backward()\n",
        "        optimizer_Discriminator_C.step()\n",
        "\n",
        "        # Intermediate tracking/plotting\n",
        "        if trackSave >= saveAfter:\n",
        "                trackSave = 0\n",
        "                tensorList = makeTestTensors()\n",
        "                genList = []\n",
        "                reconList = []\n",
        "                for tensor in tensorList: # Put intermediate tensors through the G_MC and G_CM to retrieve results\n",
        "                        outGenerated = Generator_MC(tensor.to(device))\n",
        "                        outRecon = Generator_CM(outGenerated)[0].detach().cpu().numpy().T \n",
        "                        outGenerated = outGenerated[0].detach()\n",
        "                        outGenerated = torch.clip(outGenerated, -1, 1)\n",
        "                        outGenerated = ((outGenerated.cpu().numpy().T+1)*127.5).astype(int)\n",
        "                        outRecon = ((outRecon+1)*127.5).astype(int)\n",
        "                        genList.append(outGenerated)\n",
        "                        reconList.append(outRecon)\n",
        "                # Save intermediate results\n",
        "                saveTestImages(genList, reconList, epoch, i)\n",
        "                saveErrorPlots(Generators_Loss_List, Discriminator_M_Loss_List, Discriminator_C_Loss_List, adversarial_loss_list , cycle_loss_list , ssim_loss_list, Discriminator_C_FakeDecision_List, SSIMtrack, epoch ,i) \n",
        "                saveModel(epoch, Generator_MC)      "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model-15-May.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}